{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래프(Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1x2 행렬을 만드는 constant op(작업)를 만들자\n",
    "# 이 op는 default graph에 노드로 들어갈 것입니다.\n",
    "# 생성함수에서 나온 값은 constant op의 결과값 입니다.\n",
    "\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# 2x1 행렬을 만드는 constant op를 만들자\n",
    "\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# matrix1과 matrix2를 입력값으로 하는 Matmul op을 만들어 봅시다. (행렬 곱)\n",
    "# 이 op의 결과값인 product는 행렬곱의 결과를 의미\n",
    "\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "# session에서 graph 실행하기\n",
    "\n",
    "# default graph를 실행시켜 봅시다.\n",
    "sess = tf.Session()\n",
    "\n",
    "# 행렬 곱 작업을 실행하기 위해 session의 run() 메소드 호출\n",
    "# 작업 결과값인 product 값을 넘겨줍니다.\n",
    "\n",
    "# 작업에 필요한 모든 입력값들은 자동적으로 session에서 실행되며 보통은 병렬로 처리됩니다.\n",
    "# run(product)가 실행되면 2개의 상수와 1개의 행렬곱으로 3개의 op가 실행됩니다.\n",
    "# 작업의 결과물은 numpy 'ndarray' 오브젝트인 result 값으로 나옵니다.\n",
    "\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "# 예상 결과 값 = [[12.]]\n",
    "\n",
    "# 실행을 마치면 Session을 닫습니다.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## session을 쉽게 관리하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[12.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "# 쉽게 관리하기 위해 with 구문 사용\n",
    "# 자동으로 close\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([product])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU나 GPU 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[12.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # device 구문을 사용\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        # cpu : /cpu:0\n",
    "        # gpu : /gpu:0\n",
    "        # gpu_num_2 : /gpu:1\n",
    "        matrix1 = tf.constant([[3., 3.]])\n",
    "        matrix2 = tf.constant([[2.],[2.]])\n",
    "        product = tf.matmul(matrix1, matrix2)\n",
    "        \n",
    "        result = sess.run([product])\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인터렉티브(interative)한 이용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2. -1.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.Variable([1.0, 2.0])\n",
    "a = tf.constant([3.0, 3.0])\n",
    "\n",
    "# 초기화 op의 run() 메서드를 이용해서 x를 초기화\n",
    "x.initializer.run()\n",
    "\n",
    "# x에서 a를 빼는 작업을 추가하고 실행시켜서 결과를 봅시다.\n",
    "sub = tf.subtract(x, a)\n",
    "print(sub.eval())\n",
    "# eval() 메소드로 실행시킬 수 있음\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 변수(Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 값이 0인 스칼라로 초기화된 변수를 만듭시다.\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "# state에 1을 더하는 작업을 만듭니다.\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "# assign은 대입하는 메소드\n",
    "\n",
    "# 그래프를 한 번 작동시킨 후에는 init 작업을 실행해서 변수를 초기화해야 합니다. \n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# graph와 작업들을 실행\n",
    "with tf.Session() as sess:\n",
    "    # init 작업 실행\n",
    "    sess.run(init_op)\n",
    "    # state의 시작값 출력\n",
    "    print(sess.run(state))\n",
    "    # state값을 업데이트하고 출력하는 작업을 실행\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([21,  0]), array([7, 0])]\n"
     ]
    }
   ],
   "source": [
    "# 여러개 tesor를 받아오기\n",
    "import tensorflow as tf\n",
    "\n",
    "input1 = tf.constant([3, 0])\n",
    "input2 = tf.constant([2, 0])\n",
    "input3 = tf.constant([5, 0])\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.multiply(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # mul과 intermed를 각각 수행해서 출력\n",
    "    result = sess.run([mul, intermed])\n",
    "    print(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([14.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# graph의 연산에게 직접 tensor 값을 줄 수 있는 feed 메커니즘\n",
    "# tf.placeholder를 사용하여 특정 작업을 feed 작업으로 지정\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = input1 * input2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([output], feed_dict = {input1:[7.], input2:[2.]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# MNIST 데이터셋 다운로드하는 파이썬 코드\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회귀 구현하기(소프트맥스)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tensorflowkorea.gitbooks.io/tensorflow-kr/content/g3doc/images/softmax-regression-vectorequation.png\" alt=\"SoftMax\" style=\"width: 600px; height: auto;\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 784 차원의 벡터로 변형된 MNIST 이미지의 데이터를 넣으려고 합니다.\n",
    "# None은 해당차원 길이가 어떤 길이든지 될 수 있음을 의미\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# 초기값\n",
    "w = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "# w가 [784, 10]의 형태를 갖는 이유는 w에 784차원의 이미지 벡터를 곱해서 각 클래스에 대한 증거값을 나타내는 10차원 벡터를 얻고자 하기 때문\n",
    "# b는 10차원 벡터에 더하기 위해 [10]의 형태를 갖는 것입니다.\n",
    "\n",
    "# 모델 구현\n",
    "y = tf.nn.softmax(tf.matmul(x, w) + b)\n",
    "\n",
    "# matmul로 x와 w를 먼저 곱하는데 x가 먼저인 경우는 행렬 곱 순서에 따른 수행시간때문에 앞에 둔것(수행시간 고려 매우 중요!)\n",
    "# softmax 메소드는 tf.nn.softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 크로스 엔트로피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크로스 엔트로피로 효율성을 검사하는 것\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "# 우선 tf.log로 y의 각 원소의 로그 값 계산\n",
    "# y_의 각 원소를 tf.log(y)의 해당되는 원소들과 곱\n",
    "# tf.reduce_sum으로 y의 2번째 차원(reduction_indices[1] 이라는 파라미터가 주어졌으므로)의 원소들을 합합니다.\n",
    "# 마지막으로 tf.reduce_mean으로 배치(batch)의 모든 예시에 대한 평균을 계산합니다.\n",
    "# 단, 수학적으로 불안정한 계산\n",
    "# 정규화되지 않은 로짓(logit)에 대해 tf.nn.softmax_cross-entropy_with_logits을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "# 여기서는 텐서플로우에게 학습 비율 0.5로 경사 하강법을 적용하여 크로스 엔트로피를 최소화하도록 지시\n",
    "# 경사하강법이란, 텐서플로우가 각각의 변수를 비용을 줄이는 방향으로 조금씩 이동시키는 매우 단순한 방법(최적화 알고리즘)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 학습을 1000번\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9191\n"
     ]
    }
   ],
   "source": [
    "# 우선 모델이 라벨을 올바르게 예측했는지 확인\n",
    "# tf.argmax는 텐서 안에서 특정 축을 따라 가장 큰 값의 인덱스를 찾기에 매우 유용한 함수\n",
    "# 예로 tf.argmax(y, 1)는 우리의 모델이 생각하기에 각 데이터에 가장 적합하다고 판단한(가장 증거값이 큰) 라벨\n",
    "# tf.argmax(y_, 1)는 실제 라벨\n",
    "# tf.equal을 사용하여 예측이 맞았는지 확인\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "# 이렇게하면 부울 값으로 이루어진 리스트를 얻게 됩니다.\n",
    "# 이 값을 부동 소수점으로 바꿀 수 있습니다.\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
